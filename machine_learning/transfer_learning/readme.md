# Transfer Learning - Using Inception V3 for developing Image Classifier
# what?
- Generate Feature map for images using InceptionV3 trained model,
- Train new classifier for flowers(5 classes, can be modified for any categories) using Feature map generated by InceptionV3 model.

# How?
There are two ways to create a new image classifier by transferring the weights of InceptionV3 and combining with a N way softmax layer where N is the number of classes in flowers.

1. <B>Combine layers and Train</B> - Take all layers from InceptionV3 trained model except last fully connected layer which classify into classes and combine it new softmax layer with N neurons. While training the model, set weights of InceptionV3's layers as non trainable and just train last added layer. This technique is really slow as for all epoch, InceptionV3's layers will run for all images to generate feature map and as it contains 21802784 parameters , it takes lot of time to train it, took me almost 4 hours for 5k images with 10000 epochs using CPU.
2. <B>Multistage Processing(Much faster)</B> - Divide the training into three parts - 
Generate feature map for all images using InceptionV3 model and save it.
Create a model with single softmax layer, train it using feature map as input and save its weights.
Create a new model with all but last layers taken from InceptionV3 and add final layer of model trained in 2nd step.

I tried both ways and 2nd process was much faster than 1st , just took couple of minutes to train as compare to 4 hrs using CPU(2.6GHz, i7). So, I will be explaining about 2nd process in more details through code implemented via keras library.

# Multistage Processing

# Architecture 
<img src="https://alquarizm.files.wordpress.com/2019/03/image-4.png"/>

<p><strong>Training</strong><br /><p>As shown above in the architecture, whole process is divided into 3 parts as follows - </p></p>

<ol><li><strong>Extract Features </strong><p>Extract feature for all images of all 5 categories of flowers and generate a feature vector of size 5*N*2048 where 5 represents no. of classes, N represents no. of images in each class in training set and 2048 is the size of feature map of each image generated by Inception model.
  
  
      def get_feature_set(self):
        features_extractor_layer = InceptionV3(weights='inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=self.data_set.dim, pooling='max')
        model = keras.Sequential()
        model.add(features_extractor_layer)
        
        self.x_train = model.predict(self.x_train)
        self.x_valid = model.predict(self.x_valid)
        self.x_test = model.predict(self.x_test)
        
        self.data_set.dim = self.x_train[0].shape
        print("Feature set", self.x_train.shape)
</li>
<li><strong>Train FC and Softmax layer</strong><p>After creating feature vector for all images, create a model with dense layer and softmax. After that, train this model for M number of epochs, I trained it for 10000 epochs and got 98% accuracy on test set. 
  
    def create_model(self):
        model = keras.Sequential()
        model.add(
            keras.layers.Dense(
                self.classes,
                activation='softmax',
                input_shape=self.data_set.dim))

        model.compile(
            loss=keras.losses.categorical_crossentropy,
            optimizer=keras.optimizers.Adam(),
            metrics=['accuracy'])
        print(model.summary())
        self.model = model

    def train(self):
        checkpointer = ModelCheckpoint(
            self.model_file, verbose=0, save_best_only=True)
        self.model.fit(
            self.x_train,
            self.y_train,
            batch_size=self.batch_size,
            epochs=self.epochs,
            verbose=2,
            validation_data=(self.x_valid, self.y_valid),
            callbacks=[checkpointer])
        self.model.load_weights(self.model_file)
        keras.models.save_model(self.model, self.model_file, overwrite=True)
</p> </li>
<li><strong>Combine Inception's Layers &amp; Layer from step 2</strong><p>Once model in step 2 is trained, combine weights from Inception and model trained in step 2 to create new model and save it so that it can be used for prediction directly, without computing feature map separately.
  
    def combine_model(self, final_model):
        features_extractor_layer = InceptionV3(weights='inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=self.data_set.dim, pooling='max')
        features_extractor_layer.trainable = False
        dense_layer = keras.models.load_model(self.model_file).get_layer(index = 0)
        dense_layer.trainable = False
        model = keras.Sequential()
        model.add(features_extractor_layer)
        model.add(dense_layer)
        model.compile(
            loss=keras.losses.categorical_crossentropy,
            optimizer=keras.optimizers.Adam(),
            metrics=['accuracy'])
        print(model.summary())
        keras.models.save_model(model, final_model)
 </p></li></ol>
