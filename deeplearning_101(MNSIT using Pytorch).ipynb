{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning_101.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilkarnwal/projects/blob/master/deeplearning_101(MNSIT%20using%20Pytorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGzzi1VKTih9",
        "colab_type": "code",
        "outputId": "2691dcd2-e318-4136-a76d-6193c341ae2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
        "!gunzip *.gz\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-30 20:26:16--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]   9.45M  6.84MB/s    in 1.4s    \n",
            "\n",
            "2019-11-30 20:26:17 (6.84 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2019-11-30 20:26:19--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-11-30 20:26:19 (330 KB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2019-11-30 20:26:22--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   1.57M  3.03MB/s    in 0.5s    \n",
            "\n",
            "2019-11-30 20:26:23 (3.03 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2019-11-30 20:26:25--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-30 20:26:25 (520 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n",
            "sample_data\t\tt10k-labels-idx1-ubyte\t train-labels-idx1-ubyte\n",
            "t10k-images-idx3-ubyte\ttrain-images-idx3-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3SmMzJBVckc",
        "colab_type": "code",
        "outputId": "dde021e7-94a2-4988-d7ee-199eabb02d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "x = torch.randn(5, 3).to(device)\n",
        "y = torch.randn(5, 3, device=device)\n",
        "z = x + y\n",
        "print(z)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "tensor([[ 0.4553, -0.5451, -2.4367],\n",
            "        [-0.8844,  0.8735,  0.0250],\n",
            "        [ 0.9752,  0.4694, -2.8714],\n",
            "        [ 0.0366, -0.9532, -0.9102],\n",
            "        [ 1.5993, -0.8419, -2.8299]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjf4FPG4haCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3fH253zVdbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def load(dataset=\"training\", path=None):\n",
        "    \n",
        "    import os\n",
        "    import struct\n",
        "\n",
        "    if path is None:\n",
        "        path = '/datasets/MNIST'\n",
        "        if not os.path.isdir(path):\n",
        "            path = './MNIST'\n",
        "    if not os.path.isdir(path):\n",
        "        raise ValueError(\"Cannot find dataset at '%s'\" % path)\n",
        "\n",
        "    if dataset is \"training\":\n",
        "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
        "    elif dataset is \"testing\":\n",
        "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
        "    else:\n",
        "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
        "\n",
        "    # Load everything in some numpy arrays\n",
        "    with open(fname_lbl, 'rb') as flbl:\n",
        "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
        "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
        "\n",
        "    with open(fname_img, 'rb') as fimg:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
        "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows * cols)\n",
        "\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    lbl = lbl.astype(int)\n",
        "\n",
        "    return img, lbl\n",
        "\n",
        "\n",
        "def show(image):\n",
        "    \"\"\"\n",
        "    Render a given MNIST image provided as a column vector.\n",
        "\n",
        "    Arguments:\n",
        "        image (array): an array of shape (28*28) or (28, 28) representing a\n",
        "            grey level image of size 28 x 28. Values are expected to be in the\n",
        "            range [0, 1].\n",
        "\n",
        "    Example:\n",
        "        x, lbl = load(dataset=\"training\", path=\"/datasets/MNIST\")\n",
        "        show(x[:, 0])\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot\n",
        "    import matplotlib as mpl\n",
        "\n",
        "    rows = 28\n",
        "    cols = 28\n",
        "    if image.shape[0] != rows * cols and image.shape[0] * image.shape[1] != rows * cols:\n",
        "        raise \"the input is not an MNIST image.\"\n",
        "    fig = pyplot.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    image = image.reshape(rows, cols)\n",
        "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
        "    imgplot.set_interpolation('nearest')\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    pyplot.show()\n",
        "\n",
        "def normalize(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def label2onehot(lbl):\n",
        "    d = np.zeros((lbl.max() + 1, lbl.size))\n",
        "    d[lbl, np.arange(lbl.size)] = 1\n",
        "    return d\n",
        "\n",
        "def load_and_process(set='training'):\n",
        "    x, y = load(set,\".\")\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    x_norm = normalize(x.astype(np.float32))\n",
        "    y_onehot = label2onehot(y)\n",
        "    x_final = np.moveaxis(x_norm.reshape((28,28,1,-1)),[0,1,2,3],[-2,-1,-3,-4])\n",
        "    y_final = np.moveaxis(y_onehot,[0,1],[-1,-2])\n",
        "    print(x_final.shape, y_final.shape)\n",
        "    return (x,y),(x_final, y_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZrKvCB5eSWU",
        "colab_type": "code",
        "outputId": "b9c88e38-8b69-458c-e7d7-d709c2db2184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "(x,ytrain),(xtrain,_) = load_and_process(\"training\")\n",
        "(_,ytest),(xtest,_) = load_and_process('testing')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(60000,)\n",
            "(60000, 1, 28, 28) (60000, 10)\n",
            "(784, 10000)\n",
            "(10000,)\n",
            "(10000, 1, 28, 28) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD-rDb4CebUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = torch.from_numpy(xtrain)\n",
        "xtest = torch.from_numpy(xtest)\n",
        "ltrain = torch.from_numpy(ytrain).to(dtype=torch.long)\n",
        "ltest= torch.from_numpy(ytest).to(dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9zUEcxpiGA9",
        "colab_type": "code",
        "outputId": "341f9467-032c-4bef-c3b7-e61b833f79cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#26\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(256,120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x ):\n",
        "        size = x.size()[1:]\n",
        "        return np.prod(size)\n",
        "    \n",
        "net = LeNet()\n",
        "print(net)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkhUS1gBiOLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#29, 30\n",
        "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
        "    N = xtrain.size()[0] # Training set size\n",
        "    NB = B # Number of minibatches\n",
        "    batch_size = int(N/NB);\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=rho)\n",
        "    for epoch in range(T):\n",
        "        running_loss = 0.0\n",
        "        shuffled_indices = torch.randint(0,N,(N,))\n",
        "        for k in range(NB):\n",
        "            # Extract k-th minibatch from xtrain and ltrain\n",
        "            minibatch_indices = shuffled_indices[k*batch_size:(k+1)*batch_size]\n",
        "            inputs = xtrain[minibatch_indices,:,:,:]\n",
        "            labels = ltrain[minibatch_indices]\n",
        "            # Initialize the gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            # Forward propagation\n",
        "            outputs = net(inputs)\n",
        "            # Error evaluation\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Back propagation\n",
        "            loss.backward()\n",
        "            # Parameter update\n",
        "            optimizer.step()\n",
        "            # Print averaged loss per minibatch every 100 mini-batches\n",
        "            # Compute and print statistics\n",
        "            with torch.no_grad():\n",
        "                running_loss += loss.item()\n",
        "            if k % 100 == 99:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                (epoch + 1, k + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "                \n",
        "#net = LeNet()\n",
        "#backprop_deep(xtrain, ltrain, net, T=3, B=600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FJYNR_IiqZR",
        "colab_type": "code",
        "outputId": "867f83b2-9661-4aa6-85f1-6a9d51c465bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#31\n",
        "with torch.no_grad():\n",
        "    yinit = net(xtest)\n",
        "    _, lpred = yinit.max(1)\n",
        "    print(100 * (ltest == lpred).float().mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(91.9500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxEeCkoRihXj",
        "colab_type": "code",
        "outputId": "5152f2be-1ff0-4806-cb15-83b366f17a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#32\n",
        "xtrain = xtrain.to(device)\n",
        "ltrain = ltrain.to(device)\n",
        "xtest = xtest.to(device)\n",
        "ltest = ltest.to(device)\n",
        "net = LeNet().to(device)\n",
        "backprop_deep(xtrain, ltrain, net, T=10, B=600)\n",
        "model_path = './model_net.pth'\n",
        "torch.save(net.state_dict(), model_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.303\n",
            "[1,   200] loss: 2.301\n",
            "[1,   300] loss: 2.298\n",
            "[1,   400] loss: 2.294\n",
            "[1,   500] loss: 2.290\n",
            "[1,   600] loss: 2.283\n",
            "[2,   100] loss: 2.273\n",
            "[2,   200] loss: 2.251\n",
            "[2,   300] loss: 2.201\n",
            "[2,   400] loss: 2.034\n",
            "[2,   500] loss: 1.495\n",
            "[2,   600] loss: 0.884\n",
            "[3,   100] loss: 0.651\n",
            "[3,   200] loss: 0.543\n",
            "[3,   300] loss: 0.463\n",
            "[3,   400] loss: 0.442\n",
            "[3,   500] loss: 0.393\n",
            "[3,   600] loss: 0.367\n",
            "[4,   100] loss: 0.347\n",
            "[4,   200] loss: 0.303\n",
            "[4,   300] loss: 0.292\n",
            "[4,   400] loss: 0.270\n",
            "[4,   500] loss: 0.269\n",
            "[4,   600] loss: 0.242\n",
            "[5,   100] loss: 0.246\n",
            "[5,   200] loss: 0.213\n",
            "[5,   300] loss: 0.226\n",
            "[5,   400] loss: 0.212\n",
            "[5,   500] loss: 0.215\n",
            "[5,   600] loss: 0.197\n",
            "[6,   100] loss: 0.191\n",
            "[6,   200] loss: 0.182\n",
            "[6,   300] loss: 0.184\n",
            "[6,   400] loss: 0.159\n",
            "[6,   500] loss: 0.160\n",
            "[6,   600] loss: 0.155\n",
            "[7,   100] loss: 0.153\n",
            "[7,   200] loss: 0.155\n",
            "[7,   300] loss: 0.155\n",
            "[7,   400] loss: 0.146\n",
            "[7,   500] loss: 0.145\n",
            "[7,   600] loss: 0.142\n",
            "[8,   100] loss: 0.150\n",
            "[8,   200] loss: 0.143\n",
            "[8,   300] loss: 0.131\n",
            "[8,   400] loss: 0.129\n",
            "[8,   500] loss: 0.126\n",
            "[8,   600] loss: 0.130\n",
            "[9,   100] loss: 0.138\n",
            "[9,   200] loss: 0.115\n",
            "[9,   300] loss: 0.117\n",
            "[9,   400] loss: 0.122\n",
            "[9,   500] loss: 0.112\n",
            "[9,   600] loss: 0.124\n",
            "[10,   100] loss: 0.113\n",
            "[10,   200] loss: 0.107\n",
            "[10,   300] loss: 0.112\n",
            "[10,   400] loss: 0.099\n",
            "[10,   500] loss: 0.107\n",
            "[10,   600] loss: 0.108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb1Tt4jTiw5w",
        "colab_type": "code",
        "outputId": "9088dbf9-5f49-4b32-ae14-6b521bdef121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#33\n",
        "n_net = LeNet().to(device)\n",
        "n_net.load_state_dict(torch.load(model_path,map_location=device))\n",
        "n_net.eval()\n",
        "with torch.no_grad():\n",
        "    yinit = n_net(xtest)\n",
        "    _, lpred = yinit.max(1)\n",
        "    print(100 * (ltest == lpred).float().mean())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(96.9600, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efuS4Umui9aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}